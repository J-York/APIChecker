# LLM API 连通性测试工具

这是一个纯前端的网页工具，旨在帮助用户测试与 OpenAI API 兼容的各种大型语言模型（LLM）提供商的 API 端点。它允许您配置不同的提供商、获取可用模型列表，并向单个或多个模型发送测试请求，以验证其功能和响应。

**注意：** 本工具是纯前端应用，所有配置信息（包括 API Key）都存储在您浏览器的本地存储（Local Storage）中。请确保您的环境安全，并了解这与将密钥存储在服务器端有所不同。

## 功能与特色

1.  **提供商配置：**
    * 您可以输入任何兼容 OpenAI API 格式的 LLM 提供商的 Base URL 和 API Key。
    * **Base URL:** 输入 API 的基础地址，例如 `https://api.example.com`。通常不需要在末尾添加 `/v1`，工具会自动处理。
    * **API Key:** 输入您的 API 访问密钥。
    * **提供商名称：** 为您输入的配置起一个便于识别的名称，用于保存和管理。

2.  **保存和管理提供商：**
    * 使用 **“Save Provider”** 按钮将当前输入的 Base URL、API Key、提供商名称、当前选中的模型（或自定义模型）以及流式传输设置保存到浏览器的本地存储中。
    * 保存的提供商会显示在页面下方的列表中。
    * 对于每个保存的提供商，您可以：
        * 使用 **“Use”** 按钮快速加载该提供商的配置到输入框中。
        * 使用 **“Delete”** 按钮从本地存储中删除该提供商的配置。

3.  **导入和导出提供商数据：**
    * **导出提供商：** 点击 **“Export Providers”** 按钮，可以将所有已保存的提供商数据导出为一个 JSON 文件 (`llm_tester_providers.json`)。这方便您备份配置或在不同浏览器/设备间迁移。
    * **导入提供商：** 点击 **“Import Providers”** 按钮，选择之前导出的 JSON 文件，可以将文件中的提供商数据导入到当前浏览器的本地存储中。导入时会根据提供商名称合并或覆盖现有数据。

4.  **获取模型列表：**
    * 输入提供商的 Base URL 和 API Key 后，点击 **“Fetch Models”** 按钮，工具会尝试调用该提供商的 `/v1/models` 端点，获取可用的模型列表。
    * 获取到的模型将填充到模型选择下拉框以及多模型测试区域。

5.  **单模型测试：**
    * 从模型下拉框中选择一个获取到的模型，或者在旁边的输入框中手动输入一个模型名称。
    * 输入框下方有一个 **“Enable streaming response”** 的复选框，可以控制是否启用流式传输（Streaming）进行测试。启用流式传输时，响应会逐字显示。
    * 点击 **“Send Test Message”** 按钮，向指定的模型发送一个预设的测试消息（"Hello! This is a test."）。
    * 测试结果会显示在下方的“Result”区域，包括请求的状态和模型的响应内容。

6.  **多模型批量测试：**
    * 点击 **“Show Multi-Model Test”** 按钮可以切换到多模型测试界面。
    * 在多模型测试区域，会显示通过“Fetch Models”获取到的所有模型列表，每个模型旁边有一个复选框。
    * 您可以使用 **“Select All”** 和 **“Deselect All”** 按钮方便地选择或取消选择所有模型。
    * 点击 **“Test Selected Models”** 按钮，工具将按顺序对所有选中的模型发送测试消息（注意：批量测试目前**不**支持流式传输）。
    * 测试结果会以表格形式显示，包含每个模型的名称、测试状态（Pending, Testing, Success, Failed）以及简略的响应或错误信息。
    * 点击 **“Show Single Model Test”** 按钮可以切换回单模型测试界面。

7.  **纯前端实现：**
    * 整个工具完全由 HTML, CSS 和 JavaScript 构建，直接在浏览器中运行，无需服务器后端。
    * 所有数据（提供商配置）都保存在您的浏览器本地存储中，不会发送到任何服务器。

8.  **即时结果反馈：**
    * API 请求的状态和结果会实时显示在“Result”区域，方便您查看。
    * 批量测试提供了状态表格，清晰展示每个模型的测试进度和结果。

## 如何使用

1.  在浏览器中打开 `test.html` 文件。
2.  在“Provider Base URL”和“API Key”字段中输入您的 LLM 提供商信息。
3.  （可选）为该提供商输入一个名称，然后点击“Save Provider”保存配置。
4.  点击“Fetch Models”获取该提供商支持的模型列表。
5.  **进行单模型测试：**
    * 从下拉框选择一个模型或输入自定义模型名称。
    * 根据需要勾选/取消勾选“Enable streaming response”。
    * 点击“Send Test Message”。
    * 查看“Result”区域的输出。
6.  **进行多模型批量测试：**
    * 点击“Show Multi-Model Test”。
    * 勾选您想测试的模型（或使用全选/全不选按钮）。
    * 点击“Test Selected Models”。
    * 查看结果表格中的状态和响应。
7.  **管理保存的提供商：**
    * 在“Saved Providers”区域查看已保存的提供商列表。
    * 使用“Use”或“Delete”按钮进行操作。
    * 使用“Export Providers”和“Import Providers”按钮进行数据备份和迁移。
